# Docker Optimization - Visual Implementation Guide
## Xoe-NovAi Phase 1 v0.1.4-stable

**Quick Visual Reference for Implementation**

---

## 1ï¸âƒ£ CHAINLIT UI - Remove PyTorch (15 minutes)

### File Structure
```
Xoe-NovAi/
â”œâ”€â”€ requirements-chainlit.txt    â† EDIT THIS FILE
â”œâ”€â”€ Dockerfile.chainlit
â””â”€â”€ docker-compose.yml
```

### Edit: `requirements-chainlit.txt`

```diff
# BEFORE
langchain==0.1.14
pydantic>=2.7.4
torch>=2.2.0                     â† DELETE THIS LINE
torchaudio>=2.2.0                â† DELETE THIS LINE
torchvision>=0.17.0              â† DELETE THIS LINE (if present)
chainlit==1.0.0

# AFTER
langchain==0.1.14
pydantic>=2.7.4
chainlit==1.0.0

# Result: 800MB â†’ 280MB (520MB saved) âœ“
```

### Test
```bash
docker build -f Dockerfile.chainlit -t xoe-ui:test .
docker images | grep xoe-ui:test
# Should show ~280-350MB (was 800MB)
```

---

## 2ï¸âƒ£ API - Replace Whisper with faster-whisper (30 minutes)

### File Structure
```
Xoe-NovAi/
â”œâ”€â”€ requirements-api.txt         â† EDIT THIS FILE
â”œâ”€â”€ Dockerfile.api
â””â”€â”€ app/XNAi_rag_app/
    â”œâ”€â”€ api_routes.py           â† EDIT THIS FILE (find whisper usage)
    â””â”€â”€ services/
        â””â”€â”€ transcription.py     â† MAY NEED EDIT
```

### Step 1: Edit `requirements-api.txt`

```diff
# BEFORE
faiss-cpu==1.12.0
llama-cpp-python==0.3.16
openai-whisper>=20231117         â† DELETE
transformers>=4.36.0             â† DELETE (if only for whisper)
torch                            â† DELETE (if present)
fastapi==0.120.4
redis==6.4.0

# AFTER
faiss-cpu==1.12.0
llama-cpp-python==0.3.16
faster-whisper==1.2.1            â† ADD
ctranslate2==4.6.2               â† ADD
fastapi==0.120.4
redis==6.4.0

# Result: Saves ~600MB in dependencies âœ“
```

### Step 2: Find and Update Whisper Usage

**Find all files using whisper**:
```bash
grep -r "whisper\|from openai" app/ --include="*.py"
# Output examples:
# app/XNAi_rag_app/api_routes.py:13: import whisper
# app/services/transcription.py:1: from openai import AzureOpenAI
```

**Edit each file** (example: `app/XNAi_rag_app/api_routes.py`):

```python
# BEFORE
import whisper
from openai import AzureOpenAI

# In your transcription function:
model = whisper.load_model("base")
result = model.transcribe("audio.mp3")
return {"text": result["text"]}

# AFTER
from faster_whisper import WhisperModel

# In your transcription function:
model = WhisperModel("base", device="cpu", compute_type="int8")
segments, info = model.transcribe("audio.mp3")
return {"text": " ".join([s.text for s in segments])}
```

**Key Changes**:
```
Load model:     whisper.load_model()        â†’ WhisperModel()
Transcribe:     result = model.transcribe() â†’ segments, info = model.transcribe()
Extract text:   result["text"]              â†’ " ".join([s.text for s in segments])
Device:         GPU/CPU auto               â†’ device="cpu", compute_type="int8"
```

### Test
```bash
docker build -f Dockerfile.api -t xoe-api:test .
docker run --rm xoe-api:test python -c "
from faster_whisper import WhisperModel
model = WhisperModel('base', device='cpu', compute_type='int8')
print('âœ“ faster-whisper working')
"
```

---

## 3ï¸âƒ£ ALL DOCKERFILES - Add Site-Packages Cleanup (45 minutes)

### File Structure
```
Xoe-NovAi/
â”œâ”€â”€ Dockerfile.api           â† EDIT STAGE 2
â”œâ”€â”€ Dockerfile.chainlit      â† EDIT STAGE 2
â””â”€â”€ Dockerfile.crawl         â† EDIT STAGE 2
```

### Pattern to Add (in STAGE 2: RUNTIME)

**Find this in your Dockerfile**:
```dockerfile
# ============================================================================
# STAGE 2: RUNTIME - Minimal production image
# ============================================================================
FROM python:3.12-slim

# ... apt-get install system packages ...

COPY --from=builder /usr/local/lib/python3.12/site-packages /usr/local/lib/python3.12/site-packages

# â† ADD CLEANUP CODE HERE
```

**Add this code block**:
```dockerfile
# Aggressive cleanup: remove test files, __pycache__, .pyc files
RUN find /usr/local/lib/python3.12/site-packages -type d -name "tests" \
        -exec rm -rf {} + 2>/dev/null || true && \
    find /usr/local/lib/python3.12/site-packages -type d -name "__pycache__" \
        -exec rm -rf {} + 2>/dev/null || true && \
    find /usr/local/lib/python3.12/site-packages -type f -name "*.pyc" \
        -delete && \
    find /usr/local/lib/python3.12/site-packages -type f -name "*.pyo" \
        -delete && \
    echo "âœ“ Site-packages cleanup complete"
```

### Apply to All Three Dockerfiles

| File | Line# | Location |
|------|-------|----------|
| Dockerfile.api | ~85 | After COPY --from=builder line in STAGE 2 |
| Dockerfile.chainlit | ~52 | After COPY --from=builder line in STAGE 2 |
| Dockerfile.crawl | ~50 | After COPY --from=builder line in STAGE 2 |

### Test
```bash
for file in Dockerfile.{api,chainlit,crawl}; do
    name=$(echo $file | sed 's/Dockerfile\.//' | sed 's/api/api-test/' | sed 's/chainlit/ui-test/' | sed 's/crawl/crawler-test/')
    docker build -f $file -t xoe:$name .
done
docker images | grep xoe:
```

---

## 4ï¸âƒ£ OPTIONAL: Crawler Optimization (1-2 hours)

### Option A: Replace with Trafilatura (Recommended)

**File**: `requirements-crawl.txt`

```diff
# BEFORE
crawl4ai==0.7.3              â† DELETE (400-600MB)
beautifulsoup4==4.12.3
lxml==5.3.0
httpx==0.27.2

# AFTER
trafilatura==2.0.0           â† ADD (2MB, excellent extraction)
beautifulsoup4==4.12.3
lxml==5.3.0
httpx==0.27.2

# Result: 1.3GB â†’ 620MB (50% reduction) âœ“
```

**Code change** (in crawler):

```python
# BEFORE
from crawl4ai import AsyncWebCrawler

async def crawl(url):
    async with AsyncWebCrawler() as crawler:
        result = await crawler.arun(url)
        return result.markdown

# AFTER
import trafilatura
from trafilatura import extract

def crawl(url):
    downloaded = trafilatura.fetch_url(url)
    content = extract(downloaded)
    return content
```

### Option B: Keep crawl4ai but disable browser (Fallback)

**File**: `Dockerfile.crawl` (STAGE 2)

```dockerfile
# Add this environment variable
ENV CRAWL4AI_NO_BROWSER=true

# No code changes needed! Same API works with NO_BROWSER=true
```

**Result**: 1.3GB â†’ ~700MB (46% reduction)

---

## ğŸ“Š BEFORE â†’ AFTER COMPARISON

### File Changes Summary

```
QUICK WINS (2-4 hours work):

requirements-chainlit.txt
  - torch>=2.2.0             âŒ REMOVE
  - torchaudio>=2.2.0        âŒ REMOVE
  Result: 800MB â†’ 280MB (65% â†“)

requirements-api.txt
  - openai-whisper>=2023...  âŒ REMOVE
  + faster-whisper==1.2.1    âœ… ADD
  + ctranslate2==4.6.2       âœ… ADD
  Result: 2.84GB â†’ 2.0GB (29% â†“)

All Dockerfiles (api, chainlit, crawl)
  + Add site-packages cleanup block
  Result: Each image -50-100MB (3% â†“)

TOTAL QUICK WINS: 4.94GB â†’ 3.5GB (30% â†“)
TOTAL WITH CRAWLER: 4.94GB â†’ 2.8GB (43% â†“)
TOTAL WITH ALL OPTIMIZATIONS: 4.94GB â†’ 2.0GB (60% â†“)
```

---

## ğŸ” VERIFICATION CHECKLIST

After each change:

```bash
# 1. After removing PyTorch from Chainlit:
grep -i "torch" requirements-chainlit.txt
# Expected: (no output = success)

# 2. After replacing whisper:
grep -i "openai-whisper\|transformers" requirements-api.txt
# Expected: (no output = success)
grep -i "faster-whisper\|ctranslate2" requirements-api.txt
# Expected: (matches found = success)

# 3. After updating API code:
grep -r "faster_whisper\|WhisperModel" app/
# Expected: (matches found in updated files)
grep -r "whisper\.load_model" app/
# Expected: (no output = success, old code removed)

# 4. After adding cleanup to Dockerfiles:
grep -n "Site-packages cleanup\|__pycache__" Dockerfile.*
# Expected: (appears in all 3 files)

# 5. Build all images and check sizes:
docker build -f Dockerfile.api -t xoe-api:v2 .
docker build -f Dockerfile.chainlit -t xoe-ui:v2 .
docker build -f Dockerfile.crawl -t xoe-crawler:v2 .

docker images | grep "xoe-"
# Expected:
# xoe-api:v2              ~1.8-2.0GB
# xoe-ui:v2               ~280-350MB
# xoe-crawler:v2          ~620-700MB
```

---

## ğŸ§ª FUNCTIONAL TESTING

```bash
# Test API with faster-whisper
docker run --rm xoe-api:v2 python -c "
from faster_whisper import WhisperModel
import redis
import faiss
print('âœ“ API dependencies OK')
"

# Test Chainlit without PyTorch
docker run --rm xoe-ui:v2 python -c "
try:
    import torch
    print('âŒ ERROR: PyTorch still present!')
    exit(1)
except ImportError:
    import chainlit
    print('âœ“ Chainlit OK, PyTorch removed')
"

# Test Crawler
docker run --rm xoe-crawler:v2 python -c "
import httpx
import beautifulsoup4
try:
    import trafilatura  # If you chose Option A
except ImportError:
    pass  # If you chose Option B
print('âœ“ Crawler dependencies OK')
"
```

---

## ğŸ“‹ STEP-BY-STEP CHECKLIST

### Day 1-2: Chainlit PyTorch Removal
- [ ] Read DOCKER_OPTIMIZATION_QUICK_START.md
- [ ] Edit requirements-chainlit.txt (remove torch)
- [ ] Build and test: `docker build -f Dockerfile.chainlit`
- [ ] Verify size: ~280-350MB
- [ ] Commit: `git add requirements-chainlit.txt && git commit -m "chore: remove pytorch from chainlit"`

### Day 2-3: Whisper Replacement
- [ ] Edit requirements-api.txt (remove whisper, add faster-whisper)
- [ ] Find all whisper imports: `grep -r "whisper\|openai" app/`
- [ ] Update each import location (usually 1-3 files)
- [ ] Build and test: `docker build -f Dockerfile.api`
- [ ] Run functional test with faster-whisper
- [ ] Commit: `git add requirements-api.txt app/ && git commit -m "chore: replace whisper with faster-whisper"`

### Day 3-4: Dockerfile Cleanup
- [ ] Add cleanup block to Dockerfile.api
- [ ] Add cleanup block to Dockerfile.chainlit
- [ ] Add cleanup block to Dockerfile.crawl
- [ ] Build and test all three
- [ ] Verify sizes reduced by 50-100MB
- [ ] Commit: `git add Dockerfile.* && git commit -m "chore: add site-packages cleanup to dockerfiles"`

### Day 5: Optional Crawler Optimization
- [ ] Decide: trafilatura (Option A) or no-browser (Option B)
- [ ] Implement chosen option
- [ ] Build and test: `docker build -f Dockerfile.crawl`
- [ ] Verify size: ~620-700MB (from 1.3GB)
- [ ] Commit: `git add requirements-crawl.txt Dockerfile.crawl && git commit -m "opt: optimize crawler image"`

### Final: Documentation & PR
- [ ] Review all changes: `git log --oneline -5`
- [ ] Check sizes: `docker images | grep -E "api|ui|crawler"`
- [ ] Create PR with summary of changes
- [ ] Update deployment docs
- [ ] Get team approval
- [ ] Merge to main

---

## ğŸ¯ SUCCESS METRICS

| Metric | Before | After | Target |
|--------|--------|-------|--------|
| API Image | 2.84GB | 1.8GB | âœ… |
| Chainlit Image | 800MB | 280MB | âœ… |
| Crawler Image | 1.3GB | 620MB | âœ… |
| Total | 4.94GB | 2.7GB | âœ… |
| Build Time | ~10min | ~8min | 20% faster |
| Startup Time | ~30s | ~25s | 15% faster |

---

## â±ï¸ TIME ESTIMATE

| Task | Time | Difficulty |
|------|------|-----------|
| Chainlit PyTorch removal | 30 min | ğŸŸ¢ Easy |
| Whisper â†’ faster-whisper | 1 hour | ğŸŸ¢ Easy |
| Update API code | 30 min | ğŸŸ¢ Easy |
| Dockerfile cleanup | 1 hour | ğŸŸ¢ Easy |
| Testing & verification | 1 hour | ğŸŸ¢ Easy |
| **Quick Start Total** | **3.5 hours** | **ğŸŸ¢ Easy** |
| Crawler optimization | 1-2 hours | ğŸŸ¡ Medium |
| Full optimization | 2-4 weeks | ğŸŸ¡ Medium |

---

## ğŸ†˜ TROUBLESHOOTING

| Issue | Solution |
|-------|----------|
| `ModuleNotFoundError: faster_whisper` | Run `pip install faster-whisper` or rebuild image |
| `Build fails with missing dependency` | Check requirements file for syntax errors |
| Image size didn't reduce | Verify cleanup block was added & ran during build |
| Whisper code fails at import | Check updated code imports correctly |
| Chainlit won't start | Verify torch was fully removed, not just commented |
| Tests show errors | Run `docker run -it image bash` for debugging |

---

## ğŸ“ QUESTIONS?

- Check `DOCKER_OPTIMIZATION_QUICK_START.md` for step-by-step
- Check `DOCKER_OPTIMIZATION_STRATEGY.md` for detailed analysis
- Check `DOCKER_OPTIMIZATION_CODE_CHANGES.md` for exact code
- Search error in documentation
- Ask team on Slack

---

**Version**: 1.0  
**Created**: 2026-01-09  
**Status**: Ready for implementation  
**Expected Savings**: 2.94GB (60% reduction)

**Start here â†’ [DOCKER_OPTIMIZATION_QUICK_START.md](./DOCKER_OPTIMIZATION_QUICK_START.md) ğŸš€**
