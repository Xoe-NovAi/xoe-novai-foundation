Model card: gemma-3-1b-it-heretic-abliterated-i1-Q5_K_M.gguf
Path: models/gemma-3-1b-it-heretic-abliterated-uncensored.i1-Q5_K_M.gguf
Format: GGUF (quantized)
Primary role: Instruction-tuned Gemma 3 variant for stronger instruction following when GGUF runtimes are acceptable.
Recommended runtimes: llama.cpp / ggml.
Primary use-cases: richer instruction-following tasks when onnx runtime is not required. Use carefully with license and safety review.
Knowledge gaps / research tasks:
- Confirm lineage and any licensing clauses (the "heretic/abliterated" label indicates nonstandard fine-tune; validate legal/ethical use).
- Measure memory footprint and performance vs Gemma ONNX variant.
Next steps:
- Reserve this model for internal synthesis tasks that require stronger instruction tuning; add gating in orchestration policies.