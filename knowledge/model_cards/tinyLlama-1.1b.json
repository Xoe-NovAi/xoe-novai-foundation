{
  "model_id": "tinyLlama-1.1b",
  "task_category": "lightweight",
  "specs": {
    "parameters": "1.1B",
    "context_window": 2048,
    "quantizations": [
      "q4_k_m",
      "q8"
    ],
    "inference_speed_ryzen7": "3.2 tok/s (q4_k_m)",
    "memory_required": "1.2 GB (q4_k_m)"
  },
  "benchmarks": {
    "mmlu": {
      "score": 25.3,
      "source": "OpenCompass",
      "date": "2024-02"
    },
    "arc": {
      "score": 28.1,
      "source": "OpenCompass",
      "date": "2024-02"
    }
  },
  "ecosystem": {
    "frameworks": [
      "ollama",
      "llama.cpp",
      "vLLM"
    ],
    "verified_integrations": [
      "xnai_crawl",
      "chainlit",
      "langchain"
    ],
    "dependencies": [
      "transformers>=4.37",
      "torch>=2.0"
    ]
  },
  "competitive_analysis": {
    "strengths": [
      "Tiny footprint (1.2GB)",
      "Fast inference (3.2 tok/s)",
      "Good for edge"
    ],
    "weaknesses": [
      "Weak reasoning",
      "Poor benchmarks",
      "Limited capability"
    ],
    "alternatives": []
  },
  "research_status": "verified",
  "metadata": {
    "created_date": "2026-02-16T21:47:48.221089Z",
    "last_updated": "2026-02-16T21:47:48.221089Z",
    "researcher_notes": "Verified model for lightweight tasks. Optimized for Ryzen 7 5700U.",
    "source_links": [
      "https://huggingface.co/tinyLlama-1.1b"
    ]
  },
  "vectors": {
    "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
    "vector_index_location": "knowledge/vectors/model_cards.faiss",
    "embedding_timestamp": "2026-02-16T21:47:48.221089Z"
  }
}