{
  "model_id": "mistral-7b-instruct-v0.2",
  "task_category": "code_generation",
  "specs": {
    "parameters": "7B",
    "context_window": 8192,
    "quantizations": [
      "q4_k_m",
      "q5_k_m",
      "gguf"
    ],
    "inference_speed_ryzen7": "1.1 tok/s (q4_k_m)",
    "memory_required": "5.2 GB (q4_k_m)"
  },
  "benchmarks": {
    "humaneval": {
      "score": 71.4,
      "source": "BigCode Leaderboard",
      "date": "2024-02"
    },
    "mbpp": {
      "score": 59.2,
      "source": "Papers with Code",
      "date": "2024-02"
    }
  },
  "ecosystem": {
    "frameworks": [
      "ollama",
      "llama.cpp",
      "vLLM"
    ],
    "verified_integrations": [
      "xnai_crawl",
      "chainlit",
      "langchain"
    ],
    "dependencies": [
      "transformers>=4.37",
      "torch>=2.0"
    ]
  },
  "competitive_analysis": {
    "strengths": [
      "Excellent instruction following",
      "8K context window",
      "Fast inference"
    ],
    "weaknesses": [
      "Slightly weaker on math than DeepSeek 6.7B",
      "Memory tight on 6.6GB systems"
    ],
    "alternatives": [
      "DeepSeek Coder 6.7B",
      "Llama-2 13B Code"
    ]
  },
  "research_status": "verified",
  "metadata": {
    "created_date": "2026-02-16T21:47:48.221089Z",
    "last_updated": "2026-02-16T21:47:48.221089Z",
    "researcher_notes": "Verified model for code_generation tasks. Optimized for Ryzen 7 5700U.",
    "source_links": [
      "https://huggingface.co/mistral-7b-instruct-v0.2"
    ]
  },
  "vectors": {
    "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
    "vector_index_location": "knowledge/vectors/model_cards.faiss",
    "embedding_timestamp": "2026-02-16T21:47:48.221089Z"
  }
}