{
  "model_id": "codellama-34b",
  "task_category": "code_generation",
  "specs": {
    "parameters": "34B",
    "context_window": 8192,
    "quantizations": [
      "q4_k_m"
    ],
    "inference_speed_ryzen7": "0.4 tok/s (q4_k_m)",
    "memory_required": "20 GB (q4_k_m) - NOT VIABLE on Ryzen 7"
  },
  "benchmarks": {
    "humaneval": {
      "score": 81.1,
      "source": "BigCode Leaderboard",
      "date": "2024-02"
    },
    "mbpp": {
      "score": 68.2,
      "source": "Papers with Code",
      "date": "2024-02"
    }
  },
  "ecosystem": {
    "frameworks": [
      "ollama",
      "llama.cpp",
      "vLLM"
    ],
    "verified_integrations": [
      "xnai_crawl",
      "chainlit",
      "langchain"
    ],
    "dependencies": [
      "transformers>=4.37",
      "torch>=2.0"
    ]
  },
  "competitive_analysis": {
    "strengths": [
      "Highest code benchmarks among open models",
      "Meta official",
      "Strong reasoning"
    ],
    "weaknesses": [
      "Memory prohibitive for Ryzen 7",
      "Slow inference",
      "20GB VRAM required"
    ],
    "alternatives": [
      "DeepSeek Coder 6.7B (feasible replacement)",
      "Mistral 7B"
    ]
  },
  "research_status": "verified",
  "metadata": {
    "created_date": "2026-02-16T21:47:48.221089Z",
    "last_updated": "2026-02-16T21:47:48.221089Z",
    "researcher_notes": "Verified model for code_generation tasks. Optimized for Ryzen 7 5700U.",
    "source_links": [
      "https://huggingface.co/codellama-34b"
    ]
  },
  "vectors": {
    "embedding_model": "sentence-transformers/all-MiniLM-L6-v2",
    "vector_index_location": "knowledge/vectors/model_cards.faiss",
    "embedding_timestamp": "2026-02-16T21:47:48.221089Z"
  }
}